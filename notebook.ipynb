{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of contents:\n",
    "\n",
    "1. [Importing Libraries](#Libraries)\n",
    "2. [Loading Data](#Data)\n",
    "3. [Data Understanding](#Exploration)\n",
    "4. [Exploratory Data Analysis](#EDA)\n",
    "5. [Data Preprocessing](#Clean)\n",
    "6. [Model Archetecture](#Modelling)\n",
    "7. [Model Training](#Training)\n",
    "8. [Model Testing](#Validation)\n",
    "9. [Model Tuning](#Tuning)\n",
    "10. [Model Prediction](#Testing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"Libraries\"></a>\n",
    "<h1> 1. Importing Libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import relevant libraries and Dependencies\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import glob\n",
    "from tensorflow import keras\n",
    "import string\n",
    "import tensorflow as tf\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from distance import levenshtein\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> 1.1. Set seed for Reproducibility\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"Data\"></a>\n",
    "<h1> 2. Loading Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* EMNIST\n",
    "* IAM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**2.1. EMNIST**\n",
    ">>The EMNIST dataset contains handwritten characters from the NIST Special Database 19 and the NIST Special Database 20. It includes a total of 814,255 characters, with 47 classes representing the 26 uppercase and 26 lowercase letters, as well as 10 digits and 11 special characters. Each character is represented as a 28x28 pixel grayscale image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extarct EMNIST images and labels\n",
    "import gzip\n",
    "def extract_labels(filename):\n",
    "    with gzip.open(filename, 'rb') as f:\n",
    "        magic = int.from_bytes(f.read(4), byteorder='big')\n",
    "        if magic != 2049:\n",
    "            raise ValueError(\"Invalid magic number for label file: expected 2049, but got {}\".format(magic))\n",
    "        num_labels = int.from_bytes(f.read(4), byteorder='big')\n",
    "        buf = f.read(num_labels)\n",
    "        labels = np.frombuffer(buf, dtype=np.uint8).astype(np.int64)\n",
    "        return labels\n",
    "\n",
    "def extract_data(filename):\n",
    "    with gzip.open(filename, 'rb') as f:\n",
    "        # Read magic number and number of images\n",
    "        magic = int.from_bytes(f.read(4), byteorder='big')\n",
    "        if magic != 2051:\n",
    "            raise ValueError(\"Invalid magic number for image file: expected 2051, but got {}\".format(magic))\n",
    "        num_images = int.from_bytes(f.read(4), byteorder='big', signed=False)\n",
    "\n",
    "        # Read number of rows and columns\n",
    "        rows = int.from_bytes(f.read(4), byteorder='big')\n",
    "        cols = int.from_bytes(f.read(4), byteorder='big')\n",
    "\n",
    "        # Read image data\n",
    "        buf = f.read(num_images * rows * cols)\n",
    "        data = np.frombuffer(buf, dtype=np.uint8).astype(np.float32)\n",
    "        data = data.reshape(num_images, rows, cols, 1)\n",
    "\n",
    "        return data\n",
    "\n",
    "\n",
    "# Load EMNIST dataset\n",
    "emnistDir = '/home/munyao/Desktop/flat_iron_school/Moringa/phase_5/gzip/'\n",
    "emnist_train_images = extract_data(emnistDir + 'emnist-byclass-train-images-idx3-ubyte.gz')\n",
    "emnist_train_labels = extract_labels(emnistDir + 'emnist-byclass-train-labels-idx1-ubyte.gz')\n",
    "emnist_test_images = extract_data(emnistDir + 'emnist-byclass-test-images-idx3-ubyte.gz')\n",
    "emnist_test_labels = extract_labels(emnistDir + 'emnist-byclass-test-labels-idx1-ubyte.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**2.2. IAM**\n",
    ">>The IAM dataset contains handwritten text samples from forms, letters, and other documents. It includes over 1,000 pages of handwritten text and a total of 13,353 lines of text, with a vocabulary of 6,877 words. The dataset includes both isolated word images and full text lines, with varying degrees of difficulty and quality. The text is represented as ASCII strings and the images are grayscale.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the paths to the image files and their corresponding labels for the IAM forms dataset\n",
    "iam_path = '/home/munyao/Desktop/flat_iron_school/Moringa/phase_5/IAM/forms'\n",
    "image_paths = []\n",
    "labels = []\n",
    "for subdir, _, files in os.walk(iam_path):\n",
    "    for file in files:\n",
    "        if file.endswith('.png'):\n",
    "            image_paths.append(os.path.join(subdir, file))\n",
    "            labels.append(file.split('-')[1])\n",
    "\n",
    "\n",
    "image_data = np.array(image_paths)\n",
    "iam_labels = np.array(labels)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"Exploration\"></a>\n",
    "<h1> 3. Data Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"Clean\"></a>\n",
    "<h1> 4. Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Normalize the pixel values of the images to be between 0 and 1.\n",
    "* Reshape the images to be 28x28 grayscale images with a single channel.\n",
    "* Convert the labels to one-hot encoding with the specified number of classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to preproces train and test\n",
    "def preprocess_data(train_images, train_labels, test_images, test_labels, num_classes=None):\n",
    "    # Normalize the pixel values to be between 0 and 1\n",
    "    train_images = train_images.astype('float32') / 255.0\n",
    "    test_images = test_images.astype('float32') / 255.0\n",
    "\n",
    "    # Reshape the images to be 28x28 grayscale images\n",
    "    train_images = train_images.reshape(train_images.shape[0], 28, 28, 1)\n",
    "    test_images = test_images.reshape(test_images.shape[0], 28, 28, 1)\n",
    "\n",
    "    # Convert the labels to one-hot encoding\n",
    "    train_labels = tf.keras.utils.to_categorical(train_labels-1, num_classes=num_classes)\n",
    "    test_labels = tf.keras.utils.to_categorical(test_labels-1, num_classes=num_classes)\n",
    "\n",
    "    return train_images, train_labels, test_images, test_labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> 4.1. IAM Dataset Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load images from image_paths\n",
    "image_data = []\n",
    "for path in image_paths:\n",
    "    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)  # Convert image to grayscale\n",
    "    img = cv2.resize(img, (28, 28))  # Resize the image to 28x28\n",
    "    image_data.append(img)\n",
    "\n",
    "# Convert the list of images to a numpy array\n",
    "image_data = np.array(image_data)\n",
    "\n",
    "# Add a channel dimension to the images\n",
    "image_data = np.expand_dims(image_data, axis=-1)\n",
    "\n",
    "# Convert the labels to a numpy array\n",
    "labels = np.array(iam_labels)\n",
    "\n",
    "# Reshape the images to \n",
    "image_data = image_data.reshape(-1, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "iam_train_images, iam_test_images, iam_train_labels, iam_test_labels = train_test_split(image_data, labels, test_size=0.2, random_state=SEED)\n",
    "\n",
    "# Print the shapes of the resulting arrays\n",
    "print(\"iam train image shape:\", iam_train_images.shape)\n",
    "print(\"iam test image shape:\", iam_test_images.shape)\n",
    "print(\"iam train label shape:\", iam_train_labels.shape)\n",
    "print(\"iam test label:\", iam_test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Reshape the images to 1D arrays\n",
    "# X_train = iam_train_images.reshape(iam_train_images.shape[0], -1)\n",
    "# X_test = iam_test_images.reshape(iam_test_images.shape[0], -1)\n",
    "\n",
    "# # Convert the labels to one-hot encoding\n",
    "# y_train = pd.get_dummies(iam_train_labels)\n",
    "# y_test = pd.get_dummies(iam_test_labels)\n",
    "\n",
    "# # Save the data to CSV files\n",
    "# pd.DataFrame(X_train).to_csv('iam_train_images.csv', index=False)\n",
    "# pd.DataFrame(y_train).to_csv('iam_train_labels.csv', index=False)\n",
    "# pd.DataFrame(X_test).to_csv('iam_test_images.csv', index=False)\n",
    "# pd.DataFrame(y_test).to_csv('iam_test_labels.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> 4.2. EMNIST Dataset Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the EMNIST ByClass dataset\n",
    "emnist_train_images = emnist_train_images.astype('float32') / 255.0\n",
    "emnist_train_images = np.expand_dims(emnist_train_images, axis=-1)\n",
    "\n",
    "emnist_test_images = emnist_test_images.astype('float32') / 255.0\n",
    "emnist_test_images = np.expand_dims(emnist_test_images, axis=-1)\n",
    "\n",
    "# Convert the EMNIST ByClass labels to one-hot encoding\n",
    "emnist_train_labels = np.eye(62)[emnist_train_labels]\n",
    "emnist_test_labels = np.eye(62)[emnist_test_labels]\n",
    "\n",
    "print(f'EMNIST train image shape:{emnist_train_images.shape}')\n",
    "print(f'EMNIST train lebel shape:{emnist_train_labels.shape}')\n",
    "print(f'EMNIST test image shape:{emnist_test_images.shape}')\n",
    "print(f'EMNIST test label shape:{emnist_test_labels.shape}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"Modelling\"></a>\n",
    "<h1>5. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>5.1 Model Archetecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Simple Convolutional Neural Network (CNN) with two convolutional layers and two fully connected layers. \n",
    "* We compile the model using categorical cross-entropy loss and the Adam optimizer. \n",
    "* We normalize the pixel values and reshape the images to be 28x28 grayscale images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model architecture\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3,3), padding='same', activation='relu', input_shape=(28, 28, 1)),\n",
    "    MaxPooling2D((2,2)),\n",
    "    Conv2D(64, (3,3), padding='same', activation='relu'),\n",
    "    MaxPooling2D((2,2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(62, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "opt = tf.keras.optimizers.legacy.Adam(lr=0.001)\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"Training\"></a>\n",
    "<h2>5.2. Fit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the pixel values to be between 0 and 1\n",
    "train_images = emnist_train_images.astype('float32') / 255.0\n",
    "test_images = emnist_test_images.astype('float32') / 255.0\n",
    "\n",
    "# Reshape the images to be 28x28 grayscale images\n",
    "train_images = emnist_train_images.reshape(train_images.shape[0], 28, 28, 1)\n",
    "test_images = emnist_test_images.reshape(test_images.shape[0], 28, 28, 1)\n",
    "\n",
    "# Convert the labels to one-hot encoding\n",
    "train_labels = tf.keras.utils.to_categorical(emnist_train_labels-1, num_classes=62)\n",
    "test_labels = tf.keras.utils.to_categorical(emnist_test_labels-1, num_classes=62)\n",
    "\n",
    "# Train the model\n",
    "es = EarlyStopping(monitor='val_loss', patience=3)\n",
    "penPalHistory = model.fit(train_images, train_labels, validation_split=0.1, epochs=32, callbacks=[es])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">The initial loss is 0.9920, and the accuracy is 0.7032. As the number of epochs increases, the loss decreases, and the accuracy improves for both the training and validation sets. After the 20th epoch, the final loss is 0.4337, and the accuracy is 0.8468 on the training set and the validation set's loss is 0.4095 with accuracy of 0.8546."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model to disk\n",
    "model.save('emnistModel.h5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"Validation\"></a>\n",
    "<h2>5.2. Model Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained model\n",
    "model = keras.models.load_model('penPal.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test data\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "\n",
    "# Print the test accuracy\n",
    "print('Test accuracy:', test_acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"Tuning\"></a>\n",
    "<h2>5.3. Model Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Transfer Learning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load previously trained model on emnist\n",
    "iam_model = keras.models.load_model('penPal.h5')\n",
    "\n",
    "# Replace the last layer\n",
    "num_classes = 3  \n",
    "iam_model.layers.pop()  \n",
    "iam_model.add(Dense(num_classes, activation='softmax', name='new_dense'))\n",
    "\n",
    "\n",
    "# Freeze pretrained layers\n",
    "for layer in iam_model.layers[:-1]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Compile\n",
    "opt = tf.keras.optimizers.legacy.Adam(lr=0.0001)\n",
    "iam_model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Summary\n",
    "iam_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Fit**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the pixel values to be between 0 and 1\n",
    "train_images = iam_train_images.astype('float32') / 255.0\n",
    "test_images = iam_test_images.astype('float32') / 255.0\n",
    "\n",
    "# Reshape the images to be 28x28 grayscale images\n",
    "train_images = iam_train_images.reshape(train_images.shape[0], 28, 28, 1)\n",
    "test_images = iam_test_images.reshape(test_images.shape[0], 28, 28, 1)\n",
    "\n",
    "# Convert the labels to one-hot encoding\n",
    "train_labels = tf.keras.utils.to_categorical(iam_train_labels-1, num_classes=62)\n",
    "test_labels = tf.keras.utils.to_categorical(iam_test_labels-1, num_classes=62)\n",
    "\n",
    "\n",
    "# Train the model on the IAM dataset\n",
    "es = EarlyStopping(monitor='val_loss', patience=3)\n",
    "iam_model.fit(iam_train_images, iam_train_labels, validation_split=0.1, epochs=20, callbacks=[es])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Save**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model to disk\n",
    "iam_model.save('penPalModel.h5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"Prediction\"></a>\n",
    "<h1>6. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the pixel values of the test images to the range [0, 1]\n",
    "test_images = test_images / 255.0\n",
    "\n",
    "# Reshape the test images to a 4D tensor with shape (num_samples, 28, 28, 1)\n",
    "test_images = np.reshape(test_images, (test_images.shape[0], 28, 28, 1))\n",
    "\n",
    "# Evaluate the model on the test dataset\n",
    "predictions = model.predict(test_images)\n",
    "\n",
    "# Convert the predicted probabilities to predicted labels\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Flatten the test labels to a 1D array\n",
    "test_labels_flat = np.reshape(test_labels, (test_labels.shape[0],))\n",
    "\n",
    "# Calculate the Character Error Rate (CER) and Word Error Rate (WER)\n",
    "cer = np.sum(np.not_equal(predicted_labels, test_labels_flat)) / len(test_labels_flat)\n",
    "wer = cer \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> 6.1.Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Character Error Rate.\n",
    ">It is computed as the Levenshtein distance which is the sum of the character substitutions (Sc), insertions (Ic) and deletions (Dc) that are needed to transform one string into the other, divided by the total number of characters in the groundtruth (Nc)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Word Error Rate\n",
    ">It is computed as the sum of the word substitutions (Sw), insertions (Iw) and deletions (Dw) that are required to transform one string into the other, divided by the total number of words in the groundtruth (Nw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>6.1.1. Evaluate the Model</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the CER and WER\n",
    "print(\"Character Error Rate: {:.2%}\".format(cer))\n",
    "print(\"Word Error Rate: {:.2%}\".format(wer))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">penPal is performing reasonably well for handwriting recognition. A Character Error Rate of 14.5% our model makes an error on about 1 in 7 characters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>6. Database to Store the Digitized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import relevant libraries\n",
    "import sqlite3\n",
    "conn = sqlite3.connect('digitized_notes.db')\n",
    "cursor = conn.cursor()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "penpal_env",
   "language": "python",
   "name": "penpal_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
